{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def my_image_filter(input_images):\n",
    "    conv1_weights=tf.Variable(tf.random_normal([5,5,32,32]),\n",
    "                             name='conv1_weights')\n",
    "    conv1_biases=tf.Variable(tf.zeros([32]),name='conv1_biases')\n",
    "    conv1=tf.nn.conv2d(input_images,conv1_weights,strides=[1,1,1,1],padding='SAME')\n",
    "    relu1=tf.nn.relu(conv1+conv1_biases)\n",
    "    \n",
    "    conv2_weights=tf.Variable(tf.random_normal([5,5,32,32]),\n",
    "                             name='conv2_weights')\n",
    "    conv2_biases=tf.Variable(tf.zeros([32]),name='conv2_biases')\n",
    "    conv2=tf.nn.conv2d(relu1,conv2_weights,strides=[1,1,1,1],padding='SAME')\n",
    "    return tf.nn.relu(conv2+conv2_biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image1=tf.Variable(tf.random_normal([1,28,28,32]))\n",
    "image2=tf.Variable(tf.random_normal([1,28,28,32]))\n",
    "result1=my_image_filter(image1)\n",
    "result2=my_image_filter(image2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sharing Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "variables_dict={\n",
    "    'conv1_weights':tf.Variable(tf.random_normal([5,5,32,32],name='conv1_weights')),\n",
    "    'conv1_biases':tf.Variable(tf.zeros([32]),name='conv1_biases'),\n",
    "    'conv2_weights':tf.Variable(tf.random_normal([5,5,32,32],name='conv2_weights')),\n",
    "    'conv2_biases':tf.Variable(tf.zeros([32]),name='conv2_biases'),\n",
    "}\n",
    "\n",
    "def my_image_filter(input_images,variables_dict):\n",
    "    conv1=tf.nn.conv2d(input_images,variables_dict['conv1_weights'],\n",
    "                      strides=[1,1,1,1],padding='SAME')\n",
    "    relu1=tf.nn.relu(conv1+variables_dict['conv1_biases'])\n",
    "    \n",
    "    conv2=tf.nn.conv2d(relu1,variables_dict['conv2_weights'],\n",
    "                      strides=[1,1,1,1],padding='SAME')\n",
    "    return tf.nn.relu(conv2+variables_dict['conv2_biases'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result1=my_image_filter(image1,variables_dict)\n",
    "result2=my_image_filter(image2,variables_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variable Scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_relu(input,kernel_shape,bias_shape):\n",
    "    # Create variable named 'weights'\n",
    "    weights=tf.get_variable('weights',kernel_shape,initializer=tf.random_normal_initializer())\n",
    "    # Create Variable named 'biases'\n",
    "    biases=tf.get_variable('biases',bias_shape,initializer=tf.constant_initializer(0.0))\n",
    "    conv=tf.nn.conv2d(input,weights,strides=[1,1,1,1],padding='SAME')\n",
    "    return tf.nn.relu(conv+biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tf.variable_scope() pushes a namespace for variables !\n",
    "def my_image_filter(input_images):\n",
    "    with tf.variable_scope('conv1'):\n",
    "        # Variables created here will be named 'conv1/weights', 'conv1/biases'\n",
    "        relu1=conv_relu(input_images,[5,5,32,32],[32])\n",
    "    with tf.variable_scope('conv2'):\n",
    "        # Variables created here will be named 'conv2/weights', 'conv2/biases'\n",
    "        return conv_relu(relu1,[5,5,32,32],[32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Variable conv1/weights already exists, disallowed. Did you mean to set reuse=True in VarScope? Originally defined at:\n\n  File \"<ipython-input-22-9c9cffccb199>\", line 3, in conv_relu\n    weights=tf.get_variable('weights',kernel_shape,initializer=tf.random_normal_initializer())\n  File \"<ipython-input-23-10b782c6ab87>\", line 5, in my_image_filter\n    relu1=conv_relu(input_images,[5,5,32,32],[32])\n  File \"<ipython-input-24-4a3ce1402666>\", line 1, in <module>\n    result1=my_image_filter(image1)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-4a3ce1402666>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mresult1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmy_image_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mresult2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmy_image_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-23-10b782c6ab87>\u001b[0m in \u001b[0;36mmy_image_filter\u001b[0;34m(input_images)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'conv1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;31m# Variables created here will be named 'conv1/weights', 'conv1/biases'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mrelu1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconv_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_images\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'conv2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;31m# Variables created here will be named 'conv2/weights', 'conv2/biases'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-9c9cffccb199>\u001b[0m in \u001b[0;36mconv_relu\u001b[0;34m(input, kernel_shape, bias_shape)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mconv_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkernel_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbias_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# Create variable named \"weights\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'weights'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkernel_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_normal_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;31m# Create Variable named \"biases\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mbiases\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'biases'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbias_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.pyc\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, custom_getter)\u001b[0m\n\u001b[1;32m   1020\u001b[0m       \u001b[0mcollections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaching_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m       \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       custom_getter=custom_getter)\n\u001b[0m\u001b[1;32m   1023\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.pyc\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, var_store, name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, custom_getter)\u001b[0m\n\u001b[1;32m    847\u001b[0m           \u001b[0mcollections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaching_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    848\u001b[0m           \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 849\u001b[0;31m           custom_getter=custom_getter)\n\u001b[0m\u001b[1;32m    850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    851\u001b[0m   def _get_partitioned_variable(self,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.pyc\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, custom_getter)\u001b[0m\n\u001b[1;32m    343\u001b[0m           \u001b[0mreuse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreuse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m           \u001b[0mcaching_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m           validate_shape=validate_shape)\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m   def _get_partitioned_variable(\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.pyc\u001b[0m in \u001b[0;36m_true_getter\u001b[0;34m(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape)\u001b[0m\n\u001b[1;32m    328\u001b[0m           \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mregularizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreuse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreuse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m           \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m           caching_device=caching_device, validate_shape=validate_shape)\n\u001b[0m\u001b[1;32m    331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcustom_getter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.pyc\u001b[0m in \u001b[0;36m_get_single_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape)\u001b[0m\n\u001b[1;32m    631\u001b[0m                          \u001b[0;34m\" Did you mean to set reuse=True in VarScope? \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m                          \"Originally defined at:\\n\\n%s\" % (\n\u001b[0;32m--> 633\u001b[0;31m                              name, \"\".join(traceback.format_list(tb))))\n\u001b[0m\u001b[1;32m    634\u001b[0m       \u001b[0mfound_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_vars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfound_var\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Variable conv1/weights already exists, disallowed. Did you mean to set reuse=True in VarScope? Originally defined at:\n\n  File \"<ipython-input-22-9c9cffccb199>\", line 3, in conv_relu\n    weights=tf.get_variable('weights',kernel_shape,initializer=tf.random_normal_initializer())\n  File \"<ipython-input-23-10b782c6ab87>\", line 5, in my_image_filter\n    relu1=conv_relu(input_images,[5,5,32,32],[32])\n  File \"<ipython-input-24-4a3ce1402666>\", line 1, in <module>\n    result1=my_image_filter(image1)\n"
     ]
    }
   ],
   "source": [
    "result1=my_image_filter(image1)\n",
    "result2=my_image_filter(image2) # tf.get_variable() checks existing variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope('image_filters') as scope:\n",
    "    result1=my_image_filter(image1)\n",
    "    scope.reuse_variables()\n",
    "    result2=my_image_filter(image2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding tf.get_variable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope('foo'): # tf.get_variable_scope().reuse==False\n",
    "    v=tf.get_variable('v',[1])\n",
    "assert v.name=='foo/v:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope('foo',reuse=True):\n",
    "    v1=tf.get_variable('v',[1])\n",
    "assert v1 is v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope('foo',reuse=True):\n",
    "    v1=tf.get_variable('v',[1])\n",
    "assert v1.name=='foo/v:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function get_variable in module tensorflow.python.ops.variable_scope:\n",
      "\n",
      "get_variable(name, shape=None, dtype=None, initializer=None, regularizer=None, trainable=True, collections=None, caching_device=None, partitioner=None, validate_shape=True, custom_getter=None)\n",
      "    Gets an existing variable with these parameters or create a new one.\n",
      "    \n",
      "    This function prefixes the name with the current variable scope\n",
      "    and performs reuse checks. See the\n",
      "    [Variable Scope How To](../../how_tos/variable_scope/index.md)\n",
      "    for an extensive description of how reusing works. Here is a basic example:\n",
      "    \n",
      "    ```python\n",
      "    with tf.variable_scope(\"foo\"):\n",
      "        v = tf.get_variable(\"v\", [1])  # v.name == \"foo/v:0\"\n",
      "        w = tf.get_variable(\"w\", [1])  # w.name == \"foo/w:0\"\n",
      "    with tf.variable_scope(\"foo\", reuse=True)\n",
      "        v1 = tf.get_variable(\"v\")  # The same as v above.\n",
      "    ```\n",
      "    \n",
      "    If initializer is `None` (the default), the default initializer passed in\n",
      "    the variable scope will be used. If that one is `None` too, a\n",
      "    `uniform_unit_scaling_initializer` will be used. The initializer can also be\n",
      "    a Tensor, in which case the variable is initialized to this value and shape.\n",
      "    \n",
      "    Similarly, if the regularizer is `None` (the default), the default regularizer\n",
      "    passed in the variable scope will be used (if that is `None` too,\n",
      "    then by default no regularization is performed).\n",
      "    \n",
      "    If a partitioner is provided, first a sharded `Variable` is created\n",
      "    via `_get_partitioned_variable`, and the return value is a\n",
      "    `Tensor` composed of the shards concatenated along the partition axis.\n",
      "    \n",
      "    Some useful partitioners are available.  See, e.g.,\n",
      "    `variable_axis_size_partitioner` and `min_max_variable_partitioner`.\n",
      "    \n",
      "    Args:\n",
      "      name: The name of the new or existing variable.\n",
      "      shape: Shape of the new or existing variable.\n",
      "      dtype: Type of the new or existing variable (defaults to `DT_FLOAT`).\n",
      "      initializer: Initializer for the variable if one is created.\n",
      "      regularizer: A (Tensor -> Tensor or None) function; the result of\n",
      "        applying it on a newly created variable will be added to the collection\n",
      "        GraphKeys.REGULARIZATION_LOSSES and can be used for regularization.\n",
      "      trainable: If `True` also add the variable to the graph collection\n",
      "        `GraphKeys.TRAINABLE_VARIABLES` (see tf.Variable).\n",
      "      collections: List of graph collections keys to add the Variable to.\n",
      "        Defaults to `[GraphKeys.VARIABLES]` (see tf.Variable).\n",
      "      caching_device: Optional device string or function describing where the\n",
      "        Variable should be cached for reading.  Defaults to the Variable's\n",
      "        device.  If not `None`, caches on another device.  Typical use is to\n",
      "        cache on the device where the Ops using the Variable reside, to\n",
      "        deduplicate copying through `Switch` and other conditional statements.\n",
      "      partitioner: Optional callable that accepts a fully defined `TensorShape`\n",
      "        and `dtype` of the Variable to be created, and returns a list of\n",
      "        partitions for each axis (currently only one axis can be partitioned).\n",
      "      validate_shape: If False, allows the variable to be initialized with a\n",
      "          value of unknown shape. If True, the default, the shape of initial_value\n",
      "          must be known.\n",
      "      custom_getter: Callable that takes as a first argument the true getter, and\n",
      "        allows overwriting the internal get_variable method.\n",
      "        The signature of `custom_getter` should match that of this method,\n",
      "        but the most future-proof version will allow for changes:\n",
      "        `def custom_getter(getter, *args, **kwargs)`.  Direct access to\n",
      "        all `get_variable` parameters is also allowed:\n",
      "        `def custom_getter(getter, name, *args, **kwargs)`.  A simple identity\n",
      "        custom getter that simply creates variables with modified names is:\n",
      "        ```python\n",
      "        def custom_getter(getter, name, *args, **kwargs):\n",
      "          return getter(name + '_suffix', *args, **kwargs)\n",
      "        ```\n",
      "    \n",
      "    Returns:\n",
      "      The created or existing variable.\n",
      "    \n",
      "    Raises:\n",
      "      ValueError: when creating a new variable and shape is not declared,\n",
      "        when violating reuse during variable creation, or when `initializer` dtype\n",
      "        and `dtype` don't match. Reuse is set inside `variable_scope`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.get_variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basics of tf.variable_scope()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope('foo'):\n",
    "    with tf.variable_scope('bar'):\n",
    "        v=tf.get_variable('v',[1])\n",
    "assert v.name=='foo/bar/v:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope('foo1'):\n",
    "    v=tf.get_variable('v',[1])\n",
    "    tf.get_variable_scope().reuse_variables()\n",
    "    v1=tf.get_variable('v',[1])\n",
    "assert v1 is v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope('root'):\n",
    "    # At start, the scope is not reusing\n",
    "    assert tf.get_variable_scope().reuse==False\n",
    "    with tf.variable_scope('foo'):\n",
    "        # Opened a sub-scope, still not reusing\n",
    "        assert tf.get_variable_scope().reuse==False\n",
    "    with tf.variable_scope('foo',reuse=True):\n",
    "        # Explicitly opened a reusing scope\n",
    "        assert tf.get_variable_scope().reuse==True\n",
    "        with tf.variable_scope('bar'):\n",
    "            # Now sub-scope inherits the reuse flag\n",
    "            assert tf.get_variable_scope().reuse==True\n",
    "    # Exited the reusing scope, back to a non-reusing one\n",
    "    assert tf.get_variable_scope().reuse==False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capturing variable scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope('foo') as foo_scope:\n",
    "    v=tf.get_variable('v',[1])\n",
    "with tf.variable_scope(foo_scope):\n",
    "    w=tf.get_variable('w',[1])\n",
    "with tf.variable_scope(foo_scope,reuse=True):\n",
    "    v1=tf.get_variable('v',[1])\n",
    "    w1=tf.get_variable('w',[1])\n",
    "    \n",
    "assert v1 is v\n",
    "assert w1 is w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope(foo_scope):\n",
    "    assert foo_scope.name=='foo'\n",
    "with tf.variable_scope('bar'):\n",
    "    with tf.variable_scope('baz') as other_scope:\n",
    "        assert other_scope.name=='bar/baz'\n",
    "        with tf.variable_scope(foo_scope) as foo_scope2:\n",
    "            assert foo_scope2.name=='foo' # Not changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s=tf.InteractiveSession()\n",
    "s.run(tf.initialize_all_variables())\n",
    "with tf.variable_scope('foo',initializer=tf.constant_initializer(0.4)):\n",
    "    tf.get_variable_scope().reuse_variables()\n",
    "    v=tf.get_variable('v',[1])\n",
    "    assert v.eval()==0.4\n",
    "    w=tf.get_variable('w',[1],initializer=tf.constant_initializer(0.3))\n",
    "    assert w.eval()==0.3\n",
    "    with tf.variable_scope('bar'):\n",
    "        v=tf.get_variable('v',[1])\n",
    "        assert v.eval()==0.4\n",
    "    with tf.variable_scope('baz',initializer=tf.constant_initializer(0.2)):\n",
    "        v=tf.get_variable('v',[1])\n",
    "        assert v.eval()==0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope('foo'):\n",
    "    x=1.0+tf.get_variable('v',[1])\n",
    "assert x.op.name=='foo/add'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope('foo1'):\n",
    "    with tf.name_scope('bar'):\n",
    "        v=tf.get_variable('v',[1])\n",
    "        x=1.0+v\n",
    "assert v.name=='foo1/v:0'\n",
    "assert x.op.name=='foo1/bar/add'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
