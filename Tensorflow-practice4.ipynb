{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.models.embedding import gen_word2vec as word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flags=tf.app.flags\n",
    "flags.DEFINE_string('save_path',None,'Directory to write the model and training summaries')\n",
    "flags.DEFINE_string('train_data',None,'Training text file. E.g., unzipped file http://mattmahoney.net/dc/text8.zip')\n",
    "flags.DEFINE_string('eval_data',None,'File consisting of analogies of four tokens')\n",
    "flags.DEFINE_integer('embedding_size',200,'The embedding dimension size')\n",
    "flags.DEFINE_integer('epochs_to_train',15,'Number of epochs to train. Each epoch processes the training data once completely')\n",
    "flags.DEFINE_float('learning_rate',0.2,'Initial learning rate')\n",
    "flags.DEFINE_integer('num_neg_samples',100,'Negative samples per training example')\n",
    "flags.DEFINE_integer('batch_size',16,'Number of training examples processed per step(size of a minibatch)')\n",
    "flags.DEFINE_integer('concurrent_steps',12,'The number of concurrent training steps')\n",
    "flags.DEFINE_integer('window_size',5,'The number of words to predict to the left and right of the target word')\n",
    "flags.DEFINE_integer('min_count',5,'The minimum number of word occurrences for it to be included in the vocabulary')\n",
    "flags.DEFINE_float('subsample',1e-3,'Subsample threshold for word occurrence. Words that appear with higher frequency will be randomly down-sampled. Set to 0 to disable')\n",
    "flags.DEFINE_boolean('interactive',False,'If true, enters an IPython interactive session to play with the trained model.')\n",
    "flags.DEFINE_integer('statistics_interval',5,'Print statistics every n seconds')\n",
    "flags.DEFINE_integer('summary_interval',5,'Save training summary to file every n seconds(rounded up to statistics interval)')\n",
    "flags.DEFINE_integer('checkpoint_interval',600,'Checkpoint the model(i.e. save the parameters) every n seconds(rounded up to statistics interval)')\n",
    "\n",
    "FLAGS=flags.FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
